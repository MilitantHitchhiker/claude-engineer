{
  "text_models": {
    "anthropic": {
      "claude-3-5-sonnet-20240620": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "summarization",
          "translation",
          "code-generation",
          "analysis",
          "vision",
          "graduate-level-reasoning",
          "undergraduate-knowledge",
          "coding-proficiency",
          "visual-reasoning",
          "multilingual"
        ],
        "max_tokens": 4096,
        "context_window": 200000,
        "temperature": 1.0,
        "input_cost_per_1m_tokens": 3.00,
        "output_cost_per_1m_tokens": 15.00,
        "speed": "2x faster than Claude 3 Opus",
        "languages": [
          "English",
          "German",
          "Spanish",
          "French",
          "and more"
        ],
        "availability": [
          "Anthropic API",
          "Amazon Bedrock",
          "Google Cloud Vertex AI",
          "Claude.ai (free with rate limits)",
          "Claude iOS app (free with rate limits)"
        ]
      },
      "claude-3-opus-20240229": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "summarization",
          "translation",
          "code-generation",
          "analysis"
        ],
        "max_tokens": 4096,
        "context_window": 200000,
        "temperature": 1.0
      },
      "claude-3-haiku-20240307": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "summarization"
        ],
        "max_tokens": 4096,
        "context_window": 200000,
        "temperature": 1.0
      }
    },
    "openai": {
      "gpt-4o-mini": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "code-generation",
          "analysis",
          "summarization",
          "vision",
          "function-calling",
          "json-mode",
          "multimodal-reasoning",
          "multilingual-understanding"
        ],
        "max_tokens": 4096,
        "context_window": 128000,
        "temperature": 1.0,
        "input_cost_per_1m_tokens": 0.15,
        "output_cost_per_1m_tokens": 0.60,
        "knowledge_cutoff": "October 2023",
        "mmlu_score": 82,
        "availability": [
          "OpenAI API",
          "Assistants API",
          "Batch API"
        ],
        "planned_capabilities": [
          "audio",
          "video"
        ]
      },
      "gpt-4-0125-preview": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "code-generation",
          "analysis",
          "summarization",
          "function-calling",
          "json-mode"
        ],
        "max_tokens": 4096,
        "context_window": 128000,
        "temperature": 1.0
      },
      "gpt-3.5-turbo-0125": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "code-generation",
          "analysis",
          "function-calling",
          "json-mode"
        ],
        "max_tokens": 4096,
        "context_window": 16384,
        "temperature": 1.0,
        "mmlu_score": 69.8
      }
    },
    "groq": {
      "llama3-groq-70b-8192-tool-use-preview": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "code-generation",
          "function-calling",
          "tool-use"
        ],
        "temperature": 1.0,
        "max_tokens": 8192,
        "context_window": 8192,
        "performance": "Highest on Berkeley Function Calling Leaderboard (BFCL)",
        "training": [
          "Full fine-tuning",
          "Direct Preference Optimization (DPO)"
        ],
        "license": "Same as original Llama-3 models",
        "contamination_rate": "Low between training and test data"
      },
      "llama3-groq-8b-8192-tool-use-preview": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "code-generation",
          "function-calling",
          "tool-use"
        ],
        "temperature": 1.0,
        "max_tokens": 8192,
        "context_window": 8192,
        "training": [
          "Full fine-tuning",
          "Direct Preference Optimization (DPO)"
        ],
        "license": "Same as original Llama-3 models",
        "contamination_rate": "Low between training and test data"
      },
      "llama3-405b": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "code-generation",
          "function-calling",
          "web-search",
          "math",
          "code-execution"
        ],
        "temperature": 1.0,
        "max_tokens": 32768,
        "context_window": 32768,
        "description": "Largest and most capable openly available foundation model"
      },
      "mixtral-8x7b-32768": {
        "type": "text-generation",
        "capabilities": [
          "conversation",
          "text-completion",
          "code-generation"
        ],
        "temperature": 1.0,
        "max_tokens": 32768,
        "context_window": 32768
      }
    }
  },
  "vision_models": {
    "anthropic": {
      "claude-3-opus-20240229": {
        "type": "multimodal",
        "capabilities": [
          "image-analysis",
          "object-detection",
          "scene-description",
          "visual-question-answering"
        ],
        "max_tokens": 4096,
        "context_window": 200000,
        "temperature": 1.0
      },
      "claude-3-sonnet-20240229": {
        "type": "multimodal",
        "capabilities": [
          "image-analysis",
          "object-detection",
          "scene-description",
          "visual-question-answering"
        ],
        "max_tokens": 4096,
        "context_window": 200000,
        "temperature": 1.0
      }
    },
    "openai": {
      "gpt-4-vision-preview": {
        "type": "multimodal",
        "capabilities": [
          "image-analysis",
          "object-detection",
          "scene-description",
          "visual-question-answering"
        ],
        "max_tokens": 4096,
        "context_window": 128000,
        "temperature": 1.0
      }
    },
    "google": {
      "gemini-pro-vision": {
        "type": "multimodal",
        "capabilities": [
          "image-analysis",
          "object-detection",
          "visual-question-answering"
        ],
        "max_tokens": 2048,
        "context_window": 16384,
        "temperature": 0.9
      }
    }
  },
  "image_generation_models": {
    "openai": {
      "dall-e-3": {
        "type": "image-generation",
        "capabilities": [
          "text-to-image",
          "image-editing"
        ],
        "max_images": 1,
        "sizes": [
          "1024x1024",
          "1792x1024",
          "1024x1792"
        ],
        "quality": ["standard", "hd"],
        "style": ["vivid", "natural"]
      }
    }
  },
  "audio_models": {
    "openai": {
      "whisper-1": {
        "type": "speech-to-text",
        "capabilities": [
          "transcription",
          "translation"
        ],
        "response_format": ["json", "text", "srt", "verbose_json", "vtt"],
        "temperature": 0.0,
        "language": "en"
      }
    },
    "groq": {
      "whisper-large-v3": {
        "type": "speech-to-text",
        "capabilities": [
          "transcription",
          "translation"
        ],
        "max_file_size_mb": 25,
        "supported_file_types": [
          "mp3",
          "mp4",
          "mpeg",
          "mpga",
          "m4a",
          "wav",
          "webm"
        ],
        "response_format": ["json", "text", "srt", "verbose_json", "vtt"],
        "temperature": 0.0,
        "language": "en"
      }
    }
  },
  "embedding_models": {
    "openai": {
      "text-embedding-3-small": {
        "type": "text-embedding",
        "capabilities": [
          "semantic-search",
          "clustering",
          "recommendation"
        ],
        "dimensions": 1536,
        "max_tokens": 8191
      },
      "text-embedding-3-large": {
        "type": "text-embedding",
        "capabilities": [
          "semantic-search",
          "clustering",
          "recommendation"
        ],
        "dimensions": 3072,
        "max_tokens": 8191
      }
    }
  }
}